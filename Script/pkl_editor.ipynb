{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leggere Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "399\n"
     ]
    }
   ],
   "source": [
    "import pickle as pkl\n",
    "import torch\n",
    "import numpy as np\n",
    "all_data=[]\n",
    "\n",
    "with open('full_shape_val_data/Table/full_shape_val_data_part_2.pkl', 'rb') as f:\n",
    "    # Load the object from the file\n",
    "    temp_data = pkl.load(f)\n",
    "    # print((temp_data[0]))\n",
    "    #verts = torch.Tensor(np.asarray(verts))\n",
    "    \n",
    "    print(len(temp_data))\n",
    "    #print(temp_data[0][\"full_shape\"][\"label\"][\"grasp\"])\n",
    "    for index, info in enumerate(temp_data):\n",
    "                temp_info = {}\n",
    "                temp_info[\"shape_id\"] = info[\"shape_id\"]\n",
    "                temp_info[\"semantic class\"] = info[\"semantic class\"]\n",
    "                temp_info[\"affordance\"] = info[\"affordance\"]\n",
    "                temp_info[\"data_info\"] = info[\"full_shape\"]\n",
    "                \n",
    "                all_data.append(temp_info)\n",
    "\n",
    "\n",
    "\n",
    "#print(all_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Divido file PKL_ in dimensioni < 100mb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parte 1 salvata in full_shape_val_data\\Dishwasher\\full_shape_val_data_part_1.pkl\n",
      "Parte 1 salvata in full_shape_val_data\\Scissors\\full_shape_val_data_part_1.pkl\n",
      "Parte 1 salvata in full_shape_val_data\\StorageFurniture\\full_shape_val_data_part_1.pkl\n",
      "Parte 1 salvata in full_shape_val_data\\Faucet\\full_shape_val_data_part_1.pkl\n",
      "Parte 1 salvata in full_shape_val_data\\Bowl\\full_shape_val_data_part_1.pkl\n",
      "Parte 1 salvata in full_shape_val_data\\Bag\\full_shape_val_data_part_1.pkl\n",
      "Parte 1 salvata in full_shape_val_data\\Laptop\\full_shape_val_data_part_1.pkl\n",
      "Parte 1 salvata in full_shape_val_data\\Knife\\full_shape_val_data_part_1.pkl\n",
      "Parte 1 salvata in full_shape_val_data\\Table\\full_shape_val_data_part_1.pkl\n",
      "Parte 2 salvata in full_shape_val_data\\Table\\full_shape_val_data_part_2.pkl\n",
      "Parte 1 salvata in full_shape_val_data\\Chair\\full_shape_val_data_part_1.pkl\n",
      "Parte 2 salvata in full_shape_val_data\\Chair\\full_shape_val_data_part_2.pkl\n",
      "Parte 1 salvata in full_shape_val_data\\Hat\\full_shape_val_data_part_1.pkl\n",
      "Parte 1 salvata in full_shape_val_data\\Clock\\full_shape_val_data_part_1.pkl\n",
      "Parte 1 salvata in full_shape_val_data\\Bed\\full_shape_val_data_part_1.pkl\n",
      "Parte 1 salvata in full_shape_val_data\\Refrigerator\\full_shape_val_data_part_1.pkl\n",
      "Parte 1 salvata in full_shape_val_data\\Mug\\full_shape_val_data_part_1.pkl\n",
      "Parte 1 salvata in full_shape_val_data\\Display\\full_shape_val_data_part_1.pkl\n",
      "Parte 1 salvata in full_shape_val_data\\Keyboard\\full_shape_val_data_part_1.pkl\n",
      "Parte 1 salvata in full_shape_val_data\\Vase\\full_shape_val_data_part_1.pkl\n",
      "Parte 1 salvata in full_shape_val_data\\Microwave\\full_shape_val_data_part_1.pkl\n",
      "Parte 1 salvata in full_shape_val_data\\Door\\full_shape_val_data_part_1.pkl\n",
      "Parte 1 salvata in full_shape_val_data\\TrashCan\\full_shape_val_data_part_1.pkl\n",
      "Parte 1 salvata in full_shape_val_data\\Earphone\\full_shape_val_data_part_1.pkl\n",
      "Parte 1 salvata in full_shape_val_data\\Bottle\\full_shape_val_data_part_1.pkl\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import os\n",
    "import math\n",
    "\n",
    "def split_pkl_file(input_file,input_class):\n",
    "    # Verifica se il file di input esiste\n",
    "    if not os.path.exists(input_file):\n",
    "        print(f\"Il file {input_file} non esiste.\")\n",
    "        return\n",
    "    \n",
    "    # Calcola la dimensione massima consentita per ciascuna parte (100MB)\n",
    "    max_part_size = 100 * 1024 * 1024  # 100 MB in byte\n",
    "    \n",
    "    # Carica i dati dal file .pkl\n",
    "    with open(input_file, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "    data=[item for item in data if item[\"semantic class\"]==input_class]\n",
    "    \n",
    "    # Serializza i dati per calcolare le dimensioni effettive\n",
    "    serialized_data = pickle.dumps(data)\n",
    "    data_size = len(serialized_data)\n",
    "    \n",
    "    # Calcola il numero di parti\n",
    "    num_parts = math.ceil(data_size / max_part_size)\n",
    "    \n",
    "    # Calcola il numero di elementi per ogni parte\n",
    "    num_elements_per_part = math.ceil(len(data) / num_parts)\n",
    "    \n",
    "    # Estrai il nome del file senza estensione\n",
    "    input_file_name = os.path.splitext(os.path.basename(input_file))[0]\n",
    "    \n",
    "    # Crea la cartella di output con lo stesso nome del file di input\n",
    "    output_dir = os.path.join(os.path.dirname(input_file), input_file_name,input_class)\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    \n",
    "    # Suddividi i dati in parti e salvali in file .pkl separati\n",
    "    for i in range(num_parts):\n",
    "        start_index = i * num_elements_per_part\n",
    "        end_index = min((i + 1) * num_elements_per_part, len(data))\n",
    "        \n",
    "        # Estrai la parte corrente dei dati\n",
    "        part_data = data[start_index:end_index]\n",
    "        \n",
    "        # Crea il nome del file per la parte corrente\n",
    "        output_file = os.path.join(output_dir, f\"{input_file_name}_part_{i + 1}.pkl\")\n",
    "        \n",
    "        # Salva la parte corrente dei dati in un nuovo file .pkl\n",
    "        with open(output_file, 'wb') as f:\n",
    "            pickle.dump(part_data, f)\n",
    "        \n",
    "        print(f\"Parte {i + 1} salvata in {output_file}\")\n",
    "\n",
    "# Utilizzo\n",
    "input_class_set={'Faucet', 'Chair', 'Hat', 'Clock', 'Bed', 'Mug', 'Keyboard', 'Microwave', 'Door', 'TrashCan', 'Dishwasher', 'Scissors', 'StorageFurniture', 'Bowl', 'Bag', 'Laptop', 'Knife', 'Table', 'Refrigerator', 'Display', 'Vase', 'Earphone', 'Bottle'}\n",
    "for input_class_name in input_class_set:\n",
    "    split_pkl_file(\"full_shape_val_data.pkl\",input_class_name)  ##metti file da divedere\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DIVIDO 100MB X SEMANTIC CLASS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parte 1 salvata in full_shape_val_data\\full_shape_val_data_part_1.pkl\n",
      "Parte 2 salvata in full_shape_val_data\\full_shape_val_data_part_2.pkl\n",
      "Parte 3 salvata in full_shape_val_data\\full_shape_val_data_part_3.pkl\n",
      "Parte 4 salvata in full_shape_val_data\\full_shape_val_data_part_4.pkl\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import os\n",
    "import math\n",
    "\n",
    "def split_pkl_file(input_file):\n",
    "    # Verifica se il file di input esiste\n",
    "    if not os.path.exists(input_file):\n",
    "        print(f\"Il file {input_file} non esiste.\")\n",
    "        return\n",
    "    \n",
    "    # Calcola la dimensione massima consentita per ciascuna parte (100MB)\n",
    "    max_part_size = 100 * 1024 * 1024  # 100 MB in byte\n",
    "    \n",
    "    # Carica i dati dal file .pkl\n",
    "    with open(input_file, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "    \n",
    "    # Serializza i dati per calcolare le dimensioni effettive\n",
    "    serialized_data = pickle.dumps(data)\n",
    "    data_size = len(serialized_data)\n",
    "    \n",
    "    # Calcola il numero di parti\n",
    "    num_parts = math.ceil(data_size / max_part_size)\n",
    "    \n",
    "    # Calcola il numero di elementi per ogni parte\n",
    "    num_elements_per_part = math.ceil(len(data) / num_parts)\n",
    "    \n",
    "    # Estrai il nome del file senza estensione\n",
    "    input_file_name = os.path.splitext(os.path.basename(input_file))[0]\n",
    "    \n",
    "    # Crea la cartella di output con lo stesso nome del file di input\n",
    "    output_dir = os.path.join(os.path.dirname(input_file), input_file_name)\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    \n",
    "    # Suddividi i dati in parti e salvali in file .pkl separati\n",
    "    for i in range(num_parts):\n",
    "        start_index = i * num_elements_per_part\n",
    "        end_index = min((i + 1) * num_elements_per_part, len(data))\n",
    "        \n",
    "        # Estrai la parte corrente dei dati\n",
    "        part_data = data[start_index:end_index]\n",
    "        \n",
    "        # Crea il nome del file per la parte corrente\n",
    "        output_file = os.path.join(output_dir, f\"{input_file_name}_part_{i + 1}.pkl\")\n",
    "        \n",
    "        # Salva la parte corrente dei dati in un nuovo file .pkl\n",
    "        with open(output_file, 'wb') as f:\n",
    "            pickle.dump(part_data, f)\n",
    "        \n",
    "        print(f\"Parte {i + 1} salvata in {output_file}\")\n",
    "\n",
    "# Utilizzo\n",
    "split_pkl_file(\"full_shape_val_data.pkl\")  ##metti file da divedere\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
