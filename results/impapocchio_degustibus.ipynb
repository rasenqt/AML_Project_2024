{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "gJE61_q4M3p2"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import torch\n",
        "need_pytorch3d=False\n",
        "try:\n",
        "    import pytorch3d\n",
        "except ModuleNotFoundError:\n",
        "    need_pytorch3d=True\n",
        "if need_pytorch3d:\n",
        "    if torch.__version__.startswith(\"2.1.\") and sys.platform.startswith(\"linux\"):\n",
        "        # We try to install PyTorch3D via a released wheel.\n",
        "        pyt_version_str=torch.__version__.split(\"+\")[0].replace(\".\", \"\")\n",
        "        version_str=\"\".join([\n",
        "            f\"py3{sys.version_info.minor}_cu\",\n",
        "            torch.version.cuda.replace(\".\",\"\"),\n",
        "            f\"_pyt{pyt_version_str}\"\n",
        "        ])\n",
        "        !pip install fvcore iopath\n",
        "        !pip install --no-index --no-cache-dir pytorch3d -f https://dl.fbaipublicfiles.com/pytorch3d/packaging/wheels/{version_str}/download.html\n",
        "    else:\n",
        "        # We try to install PyTorch3D from source.\n",
        "        !pip install 'git+https://github.com/facebookresearch/pytorch3d.git@stable'\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install matplotlib==3.5.2\n",
        "!pip install git+https://github.com/openai/CLIP.git\n",
        "#!pip install torch==1.12.1 torchvision==0.13.1 torchaudio==0.12.1\n",
        "\n",
        "!pip install kaolin==0.15.0 -f https://nvidia-kaolin.s3.us-east-2.amazonaws.com/torch-2.1.0_cu121.html\n",
        "!pip install open3d"
      ],
      "metadata": {
        "id": "8CweaswYD-hZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e64f86e6-297f-4655-92b4-e51866bfd929"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: matplotlib==3.5.2 in /usr/local/lib/python3.10/dist-packages (3.5.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.5.2) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.5.2) (4.47.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.5.2) (1.4.5)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.5.2) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.5.2) (23.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.5.2) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.5.2) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.5.2) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib==3.5.2) (1.16.0)\n",
            "Collecting git+https://github.com/openai/CLIP.git\n",
            "  Cloning https://github.com/openai/CLIP.git to /tmp/pip-req-build-_a2b2ca1\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/openai/CLIP.git /tmp/pip-req-build-_a2b2ca1\n",
            "  Resolved https://github.com/openai/CLIP.git to commit a1d071733d7111c9c014f024669f959182114e33\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: ftfy in /usr/local/lib/python3.10/dist-packages (from clip==1.0) (6.1.3)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from clip==1.0) (2023.12.25)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from clip==1.0) (4.66.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from clip==1.0) (2.1.0+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from clip==1.0) (0.16.0+cu121)\n",
            "Requirement already satisfied: wcwidth<0.3.0,>=0.2.12 in /usr/local/lib/python3.10/dist-packages (from ftfy->clip==1.0) (0.2.13)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->clip==1.0) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->clip==1.0) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->clip==1.0) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->clip==1.0) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->clip==1.0) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->clip==1.0) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch->clip==1.0) (2.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision->clip==1.0) (1.23.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision->clip==1.0) (2.31.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->clip==1.0) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->clip==1.0) (2.1.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->clip==1.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->clip==1.0) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->clip==1.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->clip==1.0) (2023.11.17)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->clip==1.0) (1.3.0)\n",
            "Looking in links: https://nvidia-kaolin.s3.us-east-2.amazonaws.com/torch-2.1.0_cu121.html\n",
            "Requirement already satisfied: kaolin==0.15.0 in /usr/local/lib/python3.10/dist-packages (0.15.0)\n",
            "Requirement already satisfied: ipycanvas in /usr/local/lib/python3.10/dist-packages (from kaolin==0.15.0) (0.13.1)\n",
            "Requirement already satisfied: ipyevents in /usr/local/lib/python3.10/dist-packages (from kaolin==0.15.0) (2.0.2)\n",
            "Requirement already satisfied: jupyter-client<8 in /usr/local/lib/python3.10/dist-packages (from kaolin==0.15.0) (6.1.12)\n",
            "Requirement already satisfied: pyzmq<25 in /usr/local/lib/python3.10/dist-packages (from kaolin==0.15.0) (23.2.1)\n",
            "Requirement already satisfied: flask in /usr/local/lib/python3.10/dist-packages (from kaolin==0.15.0) (2.2.5)\n",
            "Requirement already satisfied: tornado in /usr/local/lib/python3.10/dist-packages (from kaolin==0.15.0) (6.3.2)\n",
            "Requirement already satisfied: comm>=0.1.3 in /usr/local/lib/python3.10/dist-packages (from kaolin==0.15.0) (0.2.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from kaolin==0.15.0) (1.23.5)\n",
            "Requirement already satisfied: pybind11 in /usr/local/lib/python3.10/dist-packages (from kaolin==0.15.0) (2.11.1)\n",
            "Requirement already satisfied: Pillow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from kaolin==0.15.0) (9.4.0)\n",
            "Requirement already satisfied: tqdm>=4.51.0 in /usr/local/lib/python3.10/dist-packages (from kaolin==0.15.0) (4.66.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from kaolin==0.15.0) (1.11.4)\n",
            "Requirement already satisfied: pygltflib in /usr/local/lib/python3.10/dist-packages (from kaolin==0.15.0) (1.16.1)\n",
            "Requirement already satisfied: usd-core<=23.5 in /usr/local/lib/python3.10/dist-packages (from kaolin==0.15.0) (23.5)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.10/dist-packages (from kaolin==0.15.0) (7.34.0)\n",
            "Requirement already satisfied: traitlets>=4 in /usr/local/lib/python3.10/dist-packages (from comm>=0.1.3->kaolin==0.15.0) (5.7.1)\n",
            "Requirement already satisfied: jupyter-core>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-client<8->kaolin==0.15.0) (5.7.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.10/dist-packages (from jupyter-client<8->kaolin==0.15.0) (2.8.2)\n",
            "Requirement already satisfied: Werkzeug>=2.2.2 in /usr/local/lib/python3.10/dist-packages (from flask->kaolin==0.15.0) (3.0.1)\n",
            "Requirement already satisfied: Jinja2>=3.0 in /usr/local/lib/python3.10/dist-packages (from flask->kaolin==0.15.0) (3.1.3)\n",
            "Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.10/dist-packages (from flask->kaolin==0.15.0) (2.1.2)\n",
            "Requirement already satisfied: click>=8.0 in /usr/local/lib/python3.10/dist-packages (from flask->kaolin==0.15.0) (8.1.7)\n",
            "Requirement already satisfied: ipywidgets<9,>=7.6.0 in /usr/local/lib/python3.10/dist-packages (from ipycanvas->kaolin==0.15.0) (8.1.1)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython->kaolin==0.15.0) (67.7.2)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.10/dist-packages (from ipython->kaolin==0.15.0) (0.19.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython->kaolin==0.15.0) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython->kaolin==0.15.0) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython->kaolin==0.15.0) (3.0.43)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython->kaolin==0.15.0) (2.16.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython->kaolin==0.15.0) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython->kaolin==0.15.0) (0.1.6)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython->kaolin==0.15.0) (4.9.0)\n",
            "Requirement already satisfied: dataclasses-json>=0.0.25 in /usr/local/lib/python3.10/dist-packages (from pygltflib->kaolin==0.15.0) (0.6.4)\n",
            "Requirement already satisfied: deprecated in /usr/local/lib/python3.10/dist-packages (from pygltflib->kaolin==0.15.0) (1.2.14)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json>=0.0.25->pygltflib->kaolin==0.15.0) (3.20.2)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json>=0.0.25->pygltflib->kaolin==0.15.0) (0.9.0)\n",
            "Requirement already satisfied: widgetsnbextension~=4.0.9 in /usr/local/lib/python3.10/dist-packages (from ipywidgets<9,>=7.6.0->ipycanvas->kaolin==0.15.0) (4.0.9)\n",
            "Requirement already satisfied: jupyterlab-widgets~=3.0.9 in /usr/local/lib/python3.10/dist-packages (from ipywidgets<9,>=7.6.0->ipycanvas->kaolin==0.15.0) (3.0.9)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython->kaolin==0.15.0) (0.8.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=3.0->flask->kaolin==0.15.0) (2.1.4)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core>=4.6.0->jupyter-client<8->kaolin==0.15.0) (4.2.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython->kaolin==0.15.0) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->kaolin==0.15.0) (0.2.13)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.1->jupyter-client<8->kaolin==0.15.0) (1.16.0)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from deprecated->pygltflib->kaolin==0.15.0) (1.14.1)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json>=0.0.25->pygltflib->kaolin==0.15.0) (23.2)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json>=0.0.25->pygltflib->kaolin==0.15.0) (1.0.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json>=0.0.25->pygltflib->kaolin==0.15.0) (4.5.0)\n",
            "Requirement already satisfied: open3d in /usr/local/lib/python3.10/dist-packages (0.18.0)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.10/dist-packages (from open3d) (1.23.5)\n",
            "Requirement already satisfied: dash>=2.6.0 in /usr/local/lib/python3.10/dist-packages (from open3d) (2.15.0)\n",
            "Requirement already satisfied: werkzeug>=2.2.3 in /usr/local/lib/python3.10/dist-packages (from open3d) (3.0.1)\n",
            "Requirement already satisfied: nbformat>=5.7.0 in /usr/local/lib/python3.10/dist-packages (from open3d) (5.9.2)\n",
            "Requirement already satisfied: configargparse in /usr/local/lib/python3.10/dist-packages (from open3d) (1.7)\n",
            "Requirement already satisfied: ipywidgets>=8.0.4 in /usr/local/lib/python3.10/dist-packages (from open3d) (8.1.1)\n",
            "Requirement already satisfied: addict in /usr/local/lib/python3.10/dist-packages (from open3d) (2.4.0)\n",
            "Requirement already satisfied: pillow>=9.3.0 in /usr/local/lib/python3.10/dist-packages (from open3d) (9.4.0)\n",
            "Requirement already satisfied: matplotlib>=3 in /usr/local/lib/python3.10/dist-packages (from open3d) (3.5.2)\n",
            "Requirement already satisfied: pandas>=1.0 in /usr/local/lib/python3.10/dist-packages (from open3d) (1.5.3)\n",
            "Requirement already satisfied: pyyaml>=5.4.1 in /usr/local/lib/python3.10/dist-packages (from open3d) (6.0.1)\n",
            "Requirement already satisfied: scikit-learn>=0.21 in /usr/local/lib/python3.10/dist-packages (from open3d) (1.2.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from open3d) (4.66.1)\n",
            "Requirement already satisfied: pyquaternion in /usr/local/lib/python3.10/dist-packages (from open3d) (0.9.9)\n",
            "Requirement already satisfied: Flask<3.1,>=1.0.4 in /usr/local/lib/python3.10/dist-packages (from dash>=2.6.0->open3d) (2.2.5)\n",
            "Requirement already satisfied: plotly>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from dash>=2.6.0->open3d) (5.15.0)\n",
            "Requirement already satisfied: dash-html-components==2.0.0 in /usr/local/lib/python3.10/dist-packages (from dash>=2.6.0->open3d) (2.0.0)\n",
            "Requirement already satisfied: dash-core-components==2.0.0 in /usr/local/lib/python3.10/dist-packages (from dash>=2.6.0->open3d) (2.0.0)\n",
            "Requirement already satisfied: dash-table==5.0.0 in /usr/local/lib/python3.10/dist-packages (from dash>=2.6.0->open3d) (5.0.0)\n",
            "Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from dash>=2.6.0->open3d) (4.5.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from dash>=2.6.0->open3d) (2.31.0)\n",
            "Requirement already satisfied: retrying in /usr/local/lib/python3.10/dist-packages (from dash>=2.6.0->open3d) (1.3.4)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.10/dist-packages (from dash>=2.6.0->open3d) (1.6.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from dash>=2.6.0->open3d) (67.7.2)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.10/dist-packages (from dash>=2.6.0->open3d) (7.0.1)\n",
            "Requirement already satisfied: comm>=0.1.3 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=8.0.4->open3d) (0.2.1)\n",
            "Requirement already satisfied: ipython>=6.1.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=8.0.4->open3d) (7.34.0)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=8.0.4->open3d) (5.7.1)\n",
            "Requirement already satisfied: widgetsnbextension~=4.0.9 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=8.0.4->open3d) (4.0.9)\n",
            "Requirement already satisfied: jupyterlab-widgets~=3.0.9 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=8.0.4->open3d) (3.0.9)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3->open3d) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3->open3d) (4.47.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3->open3d) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3->open3d) (23.2)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3->open3d) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3->open3d) (2.8.2)\n",
            "Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.10/dist-packages (from nbformat>=5.7.0->open3d) (2.19.1)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.10/dist-packages (from nbformat>=5.7.0->open3d) (4.19.2)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.10/dist-packages (from nbformat>=5.7.0->open3d) (5.7.1)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0->open3d) (2023.4)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21->open3d) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21->open3d) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21->open3d) (3.2.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=2.2.3->open3d) (2.1.4)\n",
            "Requirement already satisfied: Jinja2>=3.0 in /usr/local/lib/python3.10/dist-packages (from Flask<3.1,>=1.0.4->dash>=2.6.0->open3d) (3.1.3)\n",
            "Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.10/dist-packages (from Flask<3.1,>=1.0.4->dash>=2.6.0->open3d) (2.1.2)\n",
            "Requirement already satisfied: click>=8.0 in /usr/local/lib/python3.10/dist-packages (from Flask<3.1,>=1.0.4->dash>=2.6.0->open3d) (8.1.7)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.19.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (3.0.43)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (2.16.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.1.6)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (4.9.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=5.7.0->open3d) (23.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=5.7.0->open3d) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=5.7.0->open3d) (0.33.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=5.7.0->open3d) (0.17.1)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly>=5.0.0->dash>=2.6.0->open3d) (8.2.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3->open3d) (1.16.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata->dash>=2.6.0->open3d) (3.17.0)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core->nbformat>=5.7.0->open3d) (4.2.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->dash>=2.6.0->open3d) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->dash>=2.6.0->open3d) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->dash>=2.6.0->open3d) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->dash>=2.6.0->open3d) (2023.11.17)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.8.3)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.2.13)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import os\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "from math import radians\n",
        "from pytorch3d.transforms import axis_angle_to_matrix\n",
        "# Util function for loading point clouds|\n",
        "import numpy as np\n",
        "\n",
        "# Data structures and functions for rendering\n",
        "from pytorch3d.structures import Pointclouds\n",
        "from pytorch3d.vis.plotly_vis import AxisArgs, plot_batch_individually, plot_scene\n",
        "from pytorch3d.renderer import (\n",
        "    look_at_rotation,\n",
        "    look_at_view_transform,\n",
        "    FoVOrthographicCameras,\n",
        "    PointsRasterizationSettings,\n",
        "    PointsRenderer,\n",
        "    PulsarPointsRenderer,\n",
        "    PointsRasterizer,\n",
        "    AlphaCompositor,\n",
        "    NormWeightedCompositor,\n",
        "    FoVPerspectiveCameras,\n",
        "    PerspectiveCameras,\n",
        "    rotate_on_spot,\n",
        "    OrthographicCameras\n",
        ")"
      ],
      "metadata": {
        "id": "6bjzU3rLNHAm"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def render_point_cloud(point_cloud,distance,elev,azim,a1,a2,a3):\n",
        "\n",
        "  R, T = look_at_view_transform(distance, elev, azim)\n",
        "\n",
        "  angles = [radians(a1), radians(a2),radians(a3)]\n",
        "  rotation = axis_angle_to_matrix(torch.FloatTensor(angles))\n",
        "  R, T = rotate_on_spot(R, T, rotation)\n",
        "  cameras = FoVPerspectiveCameras(device=device, R=R, T=T, znear=0.01)#questa la fa di fronte\n",
        "\n",
        "  # Define the settings for rasterization and shading. Here we set the output image to be of size\n",
        "  # 512x512. As we are rendering images for visualization purposes only we will set faces_per_pixel=1\n",
        "  # and blur_radius=0.0. Refer to raster_points.py for explanations of these parameters.\n",
        "  raster_settings = PointsRasterizationSettings(\n",
        "      image_size=512,\n",
        "      radius = 0.003,\n",
        "      points_per_pixel = 10\n",
        "  )\n",
        "  renderer = PointsRenderer(\n",
        "      rasterizer=PointsRasterizer(cameras=cameras, raster_settings=raster_settings),\n",
        "      compositor=NormWeightedCompositor()\n",
        "  )\n",
        "\n",
        "\n",
        "  return renderer(point_cloud)\n",
        "  #plt.figure(figsize=(10, 10))\n",
        "  #plt.imshow(images[0, ..., :3].cpu().numpy())\n",
        "  #plt.axis(\"off\");\n",
        "def resize(image,res):\n",
        "  resized=image.permute(3, 1, 2, 0).squeeze(3)\n",
        "\n",
        "  transform = transforms.Resize((res, res))\n",
        "  out=transform(resized)\n",
        "  return out\n",
        "\n",
        "\n",
        "def generate_static_views(point_cloud,res):\n",
        "\n",
        "\n",
        "  mylist = [ resize(render_point_cloud(point_cloud,3,0,0,0,0,0),res),\n",
        "             resize(render_point_cloud(point_cloud,3,0,0,0,0,540),res),\n",
        "             resize(render_point_cloud(point_cloud,3,90,0,0,0,0),res),\n",
        "             resize(render_point_cloud(point_cloud,3,-80,-2,0,0,0),res),\n",
        "             resize(render_point_cloud(point_cloud,3,0,50,0,0,0),res)\n",
        "  ]\n",
        "\n",
        "  return mylist\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "6bOG9VHnFk4T"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup\n",
        "\n",
        "import open3d as o3d\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda:0\")\n",
        "    torch.cuda.set_device(device)\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "\n",
        "\n",
        "def segment2rgb(pred_class, colors):\n",
        "    pred_rgb = torch.zeros(pred_class.shape[0], 3).to(device)\n",
        "    for class_idx, color in enumerate(colors):\n",
        "        pred_rgb += torch.matmul(pred_class[:,class_idx].unsqueeze(1), color.unsqueeze(0))\n",
        "\n",
        "    return pred_rgb\n",
        "\n",
        "def color_point_cloud(pred_class, verts, colors):\n",
        "    pred_rgb = segment2rgb(pred_class, colors)\n",
        "    #print(pred_rgb.shape)\n",
        "    #print(verts.shape[0])\n",
        "\n",
        "    return Pointclouds(points=[verts], features=[pred_rgb])\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "5YtYt4U6NNmN"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install --upgrade pip\n",
        "!git clone https://github.com/rasenqt/AML_Project_2024.git\n",
        "#!pip install torch==2.0.1 torchvision==0.15.2 torchaudio==2.0.2\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xZ8AyvM6_AmH",
        "outputId": "2527172d-6e0c-4fd4-a84a-dede51e6bcc9"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'AML_Project_2024' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import argparse\n",
        "import clip\n",
        "import copy\n",
        "import json\n",
        "import kaolin as kal\n",
        "import kaolin.ops.mesh\n",
        "import numpy as np\n",
        "import os\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import sys\n",
        "import os\n",
        "import argparse\n",
        "sys.path.append('/content/AML_Project_2024/3DHighlighter-main')\n",
        "from itertools import permutations, product\n",
        "from neural_highlighter import NeuralHighlighter\n",
        "from Normalization import MeshNormalizer,PointCloudNormalizer\n",
        "from mesh import Mesh\n",
        "from pathlib import Path\n",
        "from render import Renderer\n",
        "from tqdm import tqdm\n",
        "from torch.autograd import grad\n",
        "from torchvision import transforms\n",
        "from utils import device, color_mesh\n",
        "\n",
        "\n",
        "def optimize_point_cloud(args):\n",
        "    # Constrain most sources of randomness\n",
        "    # (some torch backwards functions within CLIP are non-determinstic)\n",
        "    torch.manual_seed(args.seed)\n",
        "    torch.cuda.manual_seed(args.seed)\n",
        "    torch.cuda.manual_seed_all(args.seed)\n",
        "    random.seed(args.seed)\n",
        "    np.random.seed(args.seed)\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "\n",
        "    # Load CLIP model\n",
        "    clip_model, preprocess = clip.load(args.clipmodel, device, jit=args.jit)\n",
        "\n",
        "    # Adjust output resolution depending on model type\n",
        "    res = 224\n",
        "    if args.clipmodel == \"ViT-L/14@336px\":\n",
        "        res = 336\n",
        "    if args.clipmodel == \"RN50x4\":\n",
        "        res = 288\n",
        "    if args.clipmodel == \"RN50x16\":\n",
        "        res = 384\n",
        "    if args.clipmodel == \"RN50x64\":\n",
        "        res = 448\n",
        "\n",
        "    Path(os.path.join(args.output_dir, 'renders')).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    objbase, extension = os.path.splitext(os.path.basename(args.obj_path))\n",
        "    pointcloud = o3d.io.read_point_cloud(args.obj_path)\n",
        "    verts = torch.Tensor(np.asarray(pointcloud.points)).to(device)\n",
        "    print(verts.shape)\n",
        "\n",
        "\n",
        "    # Manually set RGB color (assuming you want to set all points to red)\n",
        "    manual_color = torch.tensor([0.0, 1.0, 0.0], dtype=torch.float32, device=device)\n",
        "\n",
        "    # Repeat the manual color for each vertex\n",
        "    rgb_colors = manual_color.repeat(verts.shape[0], 1)\n",
        "\n",
        "    shift = torch.mean(verts, dim=0)\n",
        "    scale = torch.max(torch.norm(verts-shift, p=2, dim=1))\n",
        "    verts=(verts-shift)/scale\n",
        "\n",
        "    point_cloud = Pointclouds(points=[verts], features=[rgb_colors])\n",
        "    #PointCloudNormalizer(point_cloud)()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # Initialize variables\n",
        "    background = None\n",
        "    if args.background is not None:\n",
        "        assert len(args.background) == 3\n",
        "        background = torch.tensor(args.background).to(device)\n",
        "    n_augs = args.n_augs\n",
        "    dir = args.output_dir\n",
        "\n",
        "    # Record command line arguments\n",
        "    with open(os.path.join(dir, 'commandline_args.txt'), 'w') as f:\n",
        "        json.dump(args.__dict__, f, indent=2)\n",
        "\n",
        "    # CLIP and Augmentation Transforms\n",
        "    clip_normalizer = transforms.Normalize((0.48145466, 0.4578275, 0.40821073), (0.26862954, 0.26130258, 0.27577711))\n",
        "    clip_transform = transforms.Compose([\n",
        "        transforms.Resize((res, res)),\n",
        "        clip_normalizer\n",
        "    ])\n",
        "    augment_transform = transforms.Compose([\n",
        "        transforms.RandomResizedCrop(res, scale=(1, 1)),\n",
        "        transforms.RandomPerspective(fill=1, p=0.8, distortion_scale=0.5),\n",
        "        clip_normalizer\n",
        "    ])\n",
        "\n",
        "    # MLP Settings\n",
        "    mlp = NeuralHighlighter(args.depth, args.width, out_dim=args.n_classes, positional_encoding=args.positional_encoding,\n",
        "                            sigma=args.sigma).to(device)\n",
        "    optim = torch.optim.Adam(mlp.parameters(), args.learning_rate)\n",
        "\n",
        "    # list of possible colors\n",
        "    rgb_to_color = {(204/255, 1., 0.): \"highlighter\", (180/255, 180/255, 180/255): \"gray\"}\n",
        "    color_to_rgb = {\"highlighter\": [204/255, 1., 0.], \"gray\": [180/255, 180/255, 180/255]}\n",
        "    full_colors = [[204/255, 1., 0.], [180/255, 180/255, 180/255]]\n",
        "    colors = torch.tensor(full_colors).to(device)\n",
        "\n",
        "\n",
        "    # --- Prompt ---\n",
        "    # pre-process multi_word_inputs\n",
        "    args.object[0] = ' '.join(args.object[0].split('_'))\n",
        "    for i in range(len(args.classes)):\n",
        "        args.classes[i] = ' '.join(args.classes[i].split('_'))\n",
        "    # encode prompt with CLIP\n",
        "    prompt = \"A 3D render of a gray {} with highlighted {}\".format(args.object[0], args.classes[0])\n",
        "    with torch.no_grad():\n",
        "        prompt_token = clip.tokenize([prompt]).to(device)\n",
        "        encoded_text = clip_model.encode_text(prompt_token)\n",
        "        encoded_text = encoded_text / encoded_text.norm(dim=1, keepdim=True)\n",
        "\n",
        "    vertices = copy.deepcopy(verts)\n",
        "    losses = []\n",
        "\n",
        "    # Optimization loop\n",
        "    for i in tqdm(range(args.n_iter)):\n",
        "        optim.zero_grad()\n",
        "\n",
        "        # predict highlight probabilities\n",
        "        pred_class = mlp(vertices)\n",
        "\n",
        "        # color and render mesh\n",
        "        verts_curr = vertices\n",
        "        colored_point_cloud = color_point_cloud(pred_class, verts_curr, colors)\n",
        "        rendered_images = generate_static_views(colored_point_cloud,res)\n",
        "\n",
        "        # Calculate CLIP Loss\n",
        "        loss = clip_loss(args, rendered_images, encoded_text, clip_transform, augment_transform, clip_model)\n",
        "        loss.backward(retain_graph=True)\n",
        "\n",
        "        optim.step()\n",
        "\n",
        "        # update variables + record loss\n",
        "        with torch.no_grad():\n",
        "            losses.append(loss.item())\n",
        "\n",
        "        # report results\n",
        "        if i % 100 == 0:\n",
        "            print(\"Last 100 CLIP score: {}\".format(np.mean(losses[-100:])))\n",
        "            save_renders(dir, i, rendered_images)\n",
        "            with open(os.path.join(dir, \"training_info.txt\"), \"a\") as f:\n",
        "                f.write(f\"For iteration {i}... Prompt: {prompt}, Last 100 avg CLIP score: {np.mean(losses[-100:])}, CLIP score {losses[-1]}\\n\")\n",
        "\n",
        "    # re-initialize background color\n",
        "    if args.background is not None:\n",
        "        assert len(args.background) == 3\n",
        "        background = torch.tensor(args.background).to(device)\n",
        "    # save results\n",
        "    #save_final_results(args, dir, vertices, mlp, vertices, colors, render, background)\n",
        "\n",
        "    # Save prompts\n",
        "    with open(os.path.join(dir, prompt), \"w\") as f:\n",
        "        f.write('')\n",
        "\n",
        "\n",
        "\n",
        "# ================== HELPER FUNCTIONS =============================\n",
        "def save_final_results(args, dir, mesh, mlp, vertices, colors, render, background):\n",
        "    mlp.eval()\n",
        "    with torch.no_grad():\n",
        "        probs = mlp(vertices)\n",
        "        max_idx = torch.argmax(probs, 1, keepdim=True)\n",
        "        # for renders\n",
        "        one_hot = torch.zeros(probs.shape).to(device)\n",
        "        one_hot = one_hot.scatter_(1, max_idx, 1)\n",
        "        sampled_mesh = mesh\n",
        "\n",
        "        highlight = torch.tensor([204, 255, 0]).to(device)\n",
        "        gray = torch.tensor([180, 180, 180]).to(device)\n",
        "        colors = torch.stack((highlight/255, gray/255)).to(device)\n",
        "        color_mesh(one_hot, sampled_mesh, colors)\n",
        "        rendered_images, _, _ = render.render_views(sampled_mesh, num_views=args.n_views,\n",
        "                                                                        show=args.show,\n",
        "                                                                        center_azim=args.frontview_center[0],\n",
        "                                                                        center_elev=args.frontview_center[1],\n",
        "                                                                        std=args.frontview_std,\n",
        "                                                                        return_views=True,\n",
        "                                                                        lighting=True,\n",
        "                                                                        background=background)\n",
        "        # for mesh\n",
        "        final_color = torch.zeros(vertices.shape[0], 3).to(device)\n",
        "        final_color = torch.where(max_idx==0, highlight, gray)\n",
        "        objbase, extension = os.path.splitext(os.path.basename(args.obj_path))\n",
        "        mesh.export(os.path.join(dir, f\"{objbase}_{args.classes[0]}.ply\"), extension=\"ply\", color=final_color)\n",
        "        save_renders(dir, 0, rendered_images, name='final_render.jpg')\n",
        "\n",
        "\n",
        "def clip_loss(args, rendered_images, encoded_text, clip_transform, augment_transform, clip_model):\n",
        "    if args.n_augs == 0:\n",
        "        clip_image = clip_transform(rendered_images)\n",
        "        encoded_renders = clip_model.encode_image(clip_image)\n",
        "        encoded_renders = encoded_renders / encoded_renders.norm(dim=1, keepdim=True)\n",
        "        if args.clipavg == \"view\":\n",
        "            if encoded_text.shape[0] > 1:\n",
        "                loss = torch.cosine_similarity(torch.mean(encoded_renders, dim=0),\n",
        "                                                torch.mean(encoded_text, dim=0), dim=0)\n",
        "            else:\n",
        "                loss = torch.cosine_similarity(torch.mean(encoded_renders, dim=0, keepdim=True),\n",
        "                                                encoded_text)\n",
        "        else:\n",
        "            loss = torch.mean(torch.cosine_similarity(encoded_renders, encoded_text))\n",
        "    elif args.n_augs > 0:\n",
        "        loss = 0.0\n",
        "        for _ in range(args.n_augs):\n",
        "            augmented_image = augment_transform(rendered_images)\n",
        "            encoded_renders = clip_model.encode_image(augmented_image)\n",
        "            if args.clipavg == \"view\":\n",
        "                if encoded_text.shape[0] > 1:\n",
        "                    loss -= torch.cosine_similarity(torch.mean(encoded_renders, dim=0),\n",
        "                                                    torch.mean(encoded_text, dim=0), dim=0)\n",
        "                else:\n",
        "                    loss -= torch.cosine_similarity(torch.mean(encoded_renders, dim=0, keepdim=True),\n",
        "                                                    encoded_text)\n",
        "            else:\n",
        "                loss -= torch.mean(torch.cosine_similarity(encoded_renders, encoded_text))\n",
        "    return loss\n",
        "\n",
        "def save_renders(dir, i, rendered_images, name=None):\n",
        "    if name is not None:\n",
        "        torchvision.utils.save_image(rendered_images, os.path.join(dir, name))\n",
        "    else:\n",
        "        torchvision.utils.save_image(rendered_images, os.path.join(dir, 'renders/iter_{}.jpg'.format(i)))\n",
        "\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "y59DBoOSteAI"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import os\n",
        "from io import StringIO\n",
        "import argparse\n",
        "sys.path.append('/content/AML_Project_2024/3DHighlighter-main/')\n",
        "from main import optimize # Import the function from the module\n",
        "\n",
        "class ArgsNamespace:\n",
        "    def __init__(self, args_dict):\n",
        "        self.__dict__.update(args_dict)\n",
        "\n",
        "# Create an instance of ArgsNamespace\n",
        "\n",
        "\n",
        "\n",
        "# specify the directory you want to iterate over\n",
        "#directory = './AML_Project_2024/point_cloud_dataset/'  # current directory\n",
        "directory= './AML_Project_2024/dataset/'\n",
        "\n",
        "# iterate over files in the directory\n",
        "\n",
        "for filename in os.listdir(directory):\n",
        "    #if(filename.split('.')[1]=='obj'):\n",
        "     # continue\n",
        "\n",
        "    object_name = filename.split('.')[0]\n",
        "    print(object_name)\n",
        "\n",
        "\n",
        "    args = ArgsNamespace({\n",
        "        'seed': 0,\n",
        "        'obj_path': directory + filename,\n",
        "        'output_dir': '/content/results_' + object_name,\n",
        "        'object': [object_name],\n",
        "        'classes': ['shoes'],\n",
        "        'background': [1., 1., 1.],\n",
        "        'n_views': 5,\n",
        "        'frontview_std': 4,\n",
        "        'frontview_center': [0., 0.],\n",
        "        'show': False,\n",
        "        'n_augs': 1,\n",
        "        'clipavg': 'view',\n",
        "        'render_res': 224,\n",
        "        'clipmodel': 'ViT-L/14',\n",
        "        'jit': False,\n",
        "        'depth': 4,\n",
        "        'width': 256,\n",
        "        'n_classes': 2,\n",
        "        'positional_encoding': False,\n",
        "        'sigma': 5.0,\n",
        "        'learning_rate': 0.0001,\n",
        "        'n_iter': 1\n",
        "    })\n",
        "    # Redirect standard output to capture print statements\n",
        "    old_stdout = sys.stdout\n",
        "    new_stdout = StringIO()\n",
        "    sys.stdout = new_stdout\n",
        "\n",
        "    try:\n",
        "        optimize(args)\n",
        "    finally:\n",
        "        # Reset the standard output\n",
        "        sys.stdout = old_stdout\n",
        "\n",
        "    # Print captured output\n",
        "    print(\"Output from optimize function:\")\n",
        "    print(new_stdout.getvalue())\n",
        "    print(\"porco dio\")\n",
        "    break  # You may want to remove this break depending on your requirements\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "!zip -r /content/results_television.zip /content/results_television\n",
        "files.download('/content/results_television.zip')\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        },
        "id": "2o5kCOqxNsXH",
        "outputId": "f41b84f2-35a3-4b75-c9c9-86c2c2e198b5"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bowtie\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  1.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output from optimize function:\n",
            "ModuleList(\n",
            "  (0): Linear(in_features=3, out_features=256, bias=True)\n",
            "  (1): ReLU()\n",
            "  (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "  (3): Linear(in_features=256, out_features=256, bias=True)\n",
            "  (4): ReLU()\n",
            "  (5): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "  (6): Linear(in_features=256, out_features=256, bias=True)\n",
            "  (7): ReLU()\n",
            "  (8): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "  (9): Linear(in_features=256, out_features=256, bias=True)\n",
            "  (10): ReLU()\n",
            "  (11): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "  (12): Linear(in_features=256, out_features=256, bias=True)\n",
            "  (13): ReLU()\n",
            "  (14): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "  (15): Linear(in_features=256, out_features=2, bias=True)\n",
            "  (16): Softmax(dim=1)\n",
            ")\n",
            "<built-in method type of Tensor object at 0x7f1b701da2f0>\n",
            "torch.Size([3, 224, 224])\n",
            "Last 100 CLIP score: -0.2734375\n",
            "DIOCAROGNAAa\n",
            "\n",
            "porco dio\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\n\\nfrom google.colab import files\\n\\n!zip -r /content/results_television.zip /content/results_television\\nfiles.download('/content/results_television.zip')\\n\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    }
  ]
}